{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1215f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Ready\n"
     ]
    }
   ],
   "source": [
    "import cv2                                # state of the art computer vision algorithms library\n",
    "import numpy as np                        # fundamental package for scientific computing\n",
    "import matplotlib.pyplot as plt           # 2D plotting library producing publication quality figures\n",
    "import pyrealsense2 as rs                 # Intel RealSense cross-platform open-source API\n",
    "# import pyntcloud\n",
    "# from pyntcloud import PyntCloud\n",
    "import scipy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import itertools\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "import src.realsense.dataset as rld\n",
    "import src.realsense.camera as rlc\n",
    "# import src.visual3d.geometry as geom\n",
    "import src.mymodel.gmm as mygmm\n",
    "import torch\n",
    "\n",
    "import rosbag\n",
    "from scipy import linalg\n",
    "from sklearn import mixture\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.animation as manimation\n",
    "from IPython.display import Video, clear_output\n",
    "import time\n",
    "\n",
    "print(\"Environment Ready\")\n",
    "\n",
    "# %matplotlib\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d0c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8b79db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame from bags\n",
    "bag_name = 'single_layer'\n",
    "np.random.seed(0)\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_device_from_file(f\"data/{bag_name}.bag\")\n",
    "queue = rs.frame_queue(100)\n",
    "profile = pipe.start(cfg)\n",
    "playback = profile.get_device().as_playback()\n",
    "playback.set_real_time(False)\n",
    "# video writter\n",
    "\n",
    "FFMpegWriter = manimation.writers['ffmpeg']\n",
    "metadata = dict(title='Movie Test', artist='Matplotlib',\n",
    "                comment='Movie support!')\n",
    "writer = FFMpegWriter(fps=10, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d01273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time = 0.7262 s, GMM time = 0.4897 s\n",
      "saving the 28/1000 frame\n",
      "██------------------------------------------------------------------------------ 2.80%\n",
      "elapsed time = 0.96 min, time remain = 32.02 min\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdouble)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     89\u001b[0m my_gmm \u001b[38;5;241m=\u001b[39m mygmm\u001b[38;5;241m.\u001b[39mGMM_torch(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m \u001b[43mmy_gmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m my_gmm\u001b[38;5;241m.\u001b[39mfilter_GMM(X,filter_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     92\u001b[0m my_gmm\u001b[38;5;241m.\u001b[39mmerge_GMM(X)\n",
      "File \u001b[0;32m~/vision_ws/src/vision/scripts/realsense_detection/src/mymodel/gmm.py:239\u001b[0m, in \u001b[0;36mGMM_torch.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfail_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vision_ws/src/vision/scripts/realsense_detection/src/mymodel/gmm.py:239\u001b[0m, in \u001b[0;36mGMM_torch.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfail_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping similar frames: GMM_torch.fit at line 239 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/vision_ws/src/vision/scripts/realsense_detection/src/mymodel/gmm.py:239\u001b[0m, in \u001b[0;36mGMM_torch.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfail_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/vision_ws/src/vision/scripts/realsense_detection/src/mymodel/gmm.py:236\u001b[0m, in \u001b[0;36mGMM_torch.fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm_step(X)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfail_count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m10\u001b[39m:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(torch\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights)):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfail_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "for a in range(0):\n",
    "    pipe.wait_for_frames()\n",
    "\n",
    "\n",
    "fig, axarr = plt.subplots(2,2,figsize=(11,6))\n",
    "axarr = axarr.flatten()\n",
    "total_frames = 1000\n",
    "start_time = time.time()\n",
    "\n",
    "with writer.saving(fig, f\"results/{bag_name}.mp4\", 100):\n",
    "    for frame_idx in range(total_frames):\n",
    "\n",
    "        # Store next frameset for later processing:\n",
    "        frameset = pipe.wait_for_frames()\n",
    "        color_frame = frameset.get_color_frame()\n",
    "        depth_frame = frameset.get_depth_frame()\n",
    "\n",
    "        # Cleanup:\n",
    "\n",
    "        # visualize the capture frame\n",
    "        color = np.asanyarray(color_frame.get_data())\n",
    "        colorizer = rs.colorizer()\n",
    "        colorized_depth = np.asanyarray(colorizer.colorize(depth_frame).get_data())\n",
    "        H,W = color.shape[:2]\n",
    "        gray = np.mean(colorized_depth,axis=2).astype(np.uint8)\n",
    "\n",
    "        # align rgb and depth image\n",
    "        align = rs.align(rs.stream.color)\n",
    "        frameset = align.process(frameset)\n",
    "\n",
    "        # Update color and depth frames:\n",
    "        aligned_depth_frame = frameset.get_depth_frame()\n",
    "        colorized_depth = np.asanyarray(colorizer.colorize(aligned_depth_frame).get_data())\n",
    "        depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "        depth = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth = depth*depth_scale\n",
    "\n",
    "        # get intrinsics\n",
    "        bag = rosbag.Bag('data/with_objects_multi_layer.bag')\n",
    "        count_loop = 0\n",
    "        for topic, msg, t in bag.read_messages():\n",
    "            if 'Color_0/info/camera_info' in topic:\n",
    "                K = msg.K\n",
    "            count_loop +=1\n",
    "            if count_loop > 20:\n",
    "                break\n",
    "        bag.close()\n",
    "        K = np.array(K).reshape(3,3)\n",
    "        \n",
    "        start_processing_time = time.time()\n",
    "        # simple plane segmentation\n",
    "        from sklearn import linear_model\n",
    "        xyz,rgb = rlc.project_rgbd2pcd(color,depth,K) # project to point cloud\n",
    "        idx = xyz[:,2]>0.001\n",
    "        xyz = xyz[idx,:]; rgb = rgb[idx,:]\n",
    "        xy = xyz[:,:2]; z=xyz[:,2]\n",
    "        reg = linear_model.LinearRegression()\n",
    "        reg.fit(xy,z)\n",
    "        class_binary = (z - (xy @ reg.coef_ + reg.intercept_) ) < -0.02\n",
    "        xyz_top = xyz[class_binary,:]\n",
    "        rgb_top = rgb[class_binary,:]\n",
    "        xyz_bottom = xyz[~class_binary,:]\n",
    "        rgb_bottom = rgb[~class_binary,:]\n",
    "        color_top, depth_top = rlc.project_pcd2rgb(xyz_top,rgb_top,H,W,K)\n",
    "        \n",
    "        start_gmm_time = time.time()\n",
    "        # prepare for GMM\n",
    "        x_idx = np.array([range(W) for _ in range(H)])\n",
    "        y_idx = np.array([range(H) for _ in range(W)]).T\n",
    "        binary_depth = depth_top > 0.001\n",
    "        gmm_x = x_idx[binary_depth].reshape(-1)\n",
    "        gmm_y = y_idx[binary_depth].reshape(-1)\n",
    "        gmm_xy = np.c_[gmm_x,gmm_y]\n",
    "\n",
    "        # GMM prediction\n",
    "        rand_idx = np.random.rand(len(gmm_xy))<0.01\n",
    "        X = gmm_xy[rand_idx,:]\n",
    "#         X = gmm_xy[::20,:]\n",
    "#         dpgmm = mixture.BayesianGaussianMixture(n_components=30, covariance_type=\"full\").fit(X)\n",
    "#         my_gmm = mygmm.GMM(n_components=20, max_iter =50)\n",
    "#         my_gmm.fit(X); \n",
    "#         my_gmm.filter_GMM(X,filter_ratio=5); \n",
    "#         my_gmm.merge_GMM(X)\n",
    "#         my_gmm.filter_list = my_gmm.merge_list\n",
    "#         my_gmm.merge_GMM(X)\n",
    "#         my_gmm.filter_list = my_gmm.merge_list\n",
    "#         my_gmm.merge_GMM(X)\n",
    "        X = torch.from_numpy(X).unsqueeze(0).to(torch.double).cuda()\n",
    "        my_gmm = mygmm.GMM_torch(n_components=20, max_iter=30)\n",
    "        my_gmm.fit(X)\n",
    "        my_gmm.filter_GMM(X,filter_ratio=4)\n",
    "        my_gmm.merge_GMM(X)\n",
    "        \n",
    "        end_gmm_time = time.time()\n",
    "\n",
    "        # detect intersections\n",
    "        lines = []\n",
    "#         for i, (mean, covar) in enumerate(zip(dpgmm.means_,  dpgmm.covariances_)):\n",
    "        for i, (class_idx, mean, covar,angle,u,v) in enumerate(my_gmm.merge_list):\n",
    "        \n",
    "            p2 = mean - torch.tensor([u[1],-u[0]]).cuda()*v[1]\n",
    "            p3 = mean + torch.tensor([u[1],-u[0]]).cuda()*v[1]  \n",
    "            lines.append((p2,p3))\n",
    "        \n",
    "        # compute the poses\n",
    "        intersections = []\n",
    "        vectors1 = []\n",
    "        vectors2 = []\n",
    "        vectors3d_1 = []\n",
    "        vectors3d_2 = []\n",
    "        th_vec1_vec2 = []\n",
    "        for i in range(len(lines)):\n",
    "            for j in range(i+1,len(lines)):\n",
    "                (x1,y1),(x2,y2) = lines[i]\n",
    "                (x3,y3),(x4,y4) = lines[j]\n",
    "                px = ((x1*y2-y1*x2)*(x3-x4) - (x1-x2)*(x3*y4-y3*x4)) / ((x1-x2)*(y3-y4)-(y1-y2)*(x3-x4))\n",
    "                py = ((x1*y2-y1*x2)*(y3-y4) - (y1-y2)*(x3*y4-y3*x4)) / ((x1-x2)*(y3-y4)-(y1-y2)*(x3-x4))   \n",
    "                thres = 30\n",
    "                m1 = torch.arctan((y1-y2)/(x1-x2))\n",
    "                m2 = torch.arctan((y3-y4)/(x3-x4))\n",
    "                diff_m = min(abs(m1 - m2),np.pi-abs(m1-m2))\n",
    "                if px < max(min(x1,x2),min(x3,x4))-thres or px > min(max(x1,x2),max(x3,x4))+thres:\n",
    "                    continue\n",
    "\n",
    "                elif  diff_m < np.pi/2*0.75: # filter out the non-perpendicular pair\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    # 2d space\n",
    "                    intersections.append([px,py])\n",
    "                    v1 = torch.tensor([x2-x1,y2-y1]); v1 = v1/torch.linalg.norm(v1)\n",
    "                    v2 = torch.tensor([x4-x3,y4-y3]); v2 = v2/torch.linalg.norm(v2)\n",
    "                    vectors1.append(v1); vectors2.append(v2);th_vec1_vec2.append(np.arccos(v1@v2))\n",
    "\n",
    "#                     # 3d space\n",
    "#                     u1_temp = np.linspace(x1,x2,num=100).astype(np.int)\n",
    "#                     v1_temp = np.linspace(y1,y2,num=100).astype(np.int)\n",
    "#                     u1 = u1_temp[(u1_temp<W)&(v1_temp<H)]; v1 = v1_temp[(u1_temp<W)&(v1_temp<H)]\n",
    "#                     d1 = depth_top[v1,u1]\n",
    "#                     xyz1 = rlc.project_pixel2pcd(u1,v1,d1,K)\n",
    "#                     xyz1 = xyz1[(xyz1[:,0]>0.001)|(xyz1[:,0]<-0.001),:]\n",
    "#                     x1 = xyz1[:,0];y1 = xyz1[:,1];z1 = xyz1[:,2];t1 = np.arange(len(x1)).reshape(-1,1)\n",
    "#                     if len(x1)>20:\n",
    "#                         if x1.max() - x1.min() > 0.02:\n",
    "#                             ransac = linear_model.RANSACRegressor();ransac.fit(t1, x1);kx1 = ransac.estimator_.coef_\n",
    "#                         else:\n",
    "#                             reg = LinearRegression().fit(t1, x1);kx1 = reg.coef_\n",
    "#                         if y1.max() - y1.min() > 0.02:\n",
    "#                             ransac = linear_model.RANSACRegressor();ransac.fit(t1, y1);ky1 = ransac.estimator_.coef_\n",
    "#                         else:\n",
    "#                             reg = LinearRegression().fit(t1, y1);ky1 = reg.coef_\n",
    "#                         if z1.max() - z1.min() > 0.02:\n",
    "#                             ransac = linear_model.RANSACRegressor();ransac.fit(t1, z1);kz1 = ransac.estimator_.coef_\n",
    "#                         else:\n",
    "#                             reg = LinearRegression().fit(t1, z1);kz1 = reg.coef_\n",
    "#                     elif len(x1)>1:\n",
    "#                         reg = LinearRegression().fit(t1, x1);kx1 = reg.coef_\n",
    "#                         reg = LinearRegression().fit(t1, y1);ky1 = reg.coef_\n",
    "#                         reg = LinearRegression().fit(t1, z1);kz1 = reg.coef_\n",
    "#                     else:\n",
    "#                         kx1=ky1=kz1=0\n",
    "#                     vector1 = np.array([kx1,ky1,kz1]); \n",
    "#                     if kx1+ky1+kz1 == 0:\n",
    "#                         vector1 = np.array([0,0,0])\n",
    "#                     else:\n",
    "#                         vector1 = vector1/np.linalg.norm(vector1);\n",
    "#                     vectors3d_1.append(vector1)\n",
    "\n",
    "#                     u2_temp = np.linspace(x3,x4,num=100).astype(np.int)\n",
    "#                     v2_temp = np.linspace(y3,y4,num=100).astype(np.int)\n",
    "#                     u2 = u2_temp[(u2_temp<W)&(v2_temp<H)]; v2 = v2_temp[(u2_temp<W)&(v2_temp<H)]\n",
    "#                     d2 = depth_top[v2,u2]\n",
    "#                     xyz2 = rlc.project_pixel2pcd(u2,v2,d2,K)\n",
    "#                     xyz2 = xyz2[(xyz2[:,0]>0.001)|(xyz2[:,0]<-0.001),:]\n",
    "#                     x2 = xyz2[:,0];y2 = xyz2[:,1];z2 = xyz2[:,2];t2 = np.arange(len(x2)).reshape(-1,1)\n",
    "#                     if len(x2)>20:\n",
    "#                         if x2.max() - x2.min() > 0.02:\n",
    "#                             ransac = linear_model.RANSACRegressor();ransac.fit(t2, x2);kx2 = ransac.estimator_.coef_\n",
    "#                         else:\n",
    "#                             reg = LinearRegression().fit(t2, x2);kx2 = reg.coef_\n",
    "#                         if y2.max() - y2.min() >0.02:\n",
    "#                             ransac = linear_model.RANSACRegressor();ransac.fit(t2, y2);ky2 = ransac.estimator_.coef_\n",
    "#                         else:\n",
    "#                             reg = LinearRegression().fit(t2, y2);ky2 = reg.coef_\n",
    "#                         if z2.max() - z2.min() > 0.02:\n",
    "#                             ransac = linear_model.RANSACRegressor();ransac.fit(t2, z2);kz2 = ransac.estimator_.coef_\n",
    "#                         else:\n",
    "#                             reg = LinearRegression().fit(t2, z2);kz2 = reg.coef_                \n",
    "#                     elif len(x2)>1:\n",
    "#                         reg = LinearRegression().fit(t2, x2);kx2 = reg.coef_\n",
    "#                         reg = LinearRegression().fit(t2, y2);ky2 = reg.coef_\n",
    "#                         reg = LinearRegression().fit(t2, z2);kz2 = reg.coef_\n",
    "#                     else:\n",
    "#                         kx2=ky2=kz2=0\n",
    "#                     vector2 = np.array([kx2,ky2,kz2]); \n",
    "#                     if kx2+ky2+kz2 == 0:\n",
    "#                         vector2 = np.array([0,0,0])\n",
    "#                     else:\n",
    "#                         vector2 = vector2/np.linalg.norm(vector2);\n",
    "#                     vectors3d_2.append(vector2)\n",
    "        intersections = torch.tensor(intersections)\n",
    "        th_vec1_vec2 = torch.tensor(th_vec1_vec2)\n",
    "        th_vec1_vec2[th_vec1_vec2>np.pi/2] = np.pi - th_vec1_vec2[th_vec1_vec2>np.pi/2]\n",
    "        \n",
    "#         if th_vec1_vec2.max() - th_vec1_vec2.min()>15.0/180.0*np.pi:\n",
    "#             vector_idx = \n",
    "        \n",
    "        end_processing_time = time.time()\n",
    "        # visualize \n",
    "        # 1 - filtered\n",
    "        axarr[0].clear()\n",
    "        axarr[0].imshow(color_top)\n",
    "        axarr[0].title.set_text('slicing out top layer')\n",
    "\n",
    "#         # 2 - initial GMM\n",
    "#         axarr[1].clear()\n",
    "#         axarr[1].imshow(depth_top,cmap = \"Greys\")\n",
    "#         my_gmm.plot_results(X,gmm_list='original',ax = axarr[1])\n",
    "#         axarr[1].title.set_text('initial GMM')\n",
    "#         axarr[1].invert_yaxis()\n",
    "\n",
    "\n",
    "        # 3 - filter out fat\n",
    "#         axarr[2].clear()\n",
    "#         axarr[2].imshow(depth_top,cmap=\"Greys\")\n",
    "#         my_gmm.filter_GMM(X,filter_ratio=4) # change accordingly\n",
    "#         my_gmm.merge_GMM(X)\n",
    "#         my_gmm.filter_list = my_gmm.merge_list\n",
    "#         my_gmm.plot_results(X,gmm_list='merge_list',ax = axarr[2])\n",
    "#         axarr[2].invert_yaxis()\n",
    "#         axarr[2].title.set_text('filter out fat GMM')\n",
    "\n",
    "        #4 - generate pose\n",
    "#         axarr[3].clear()\n",
    "#         axarr[3].imshow(color)\n",
    "#         if len(intersections)!=0:\n",
    "#             axarr[3].scatter(intersections[:,0],intersections[:,1],100)\n",
    "#         for (px,py),(v1x,v1y),(v2x,v2y) in zip(intersections,vectors1,vectors2):\n",
    "#             vlength = 100\n",
    "#             if v1x<0:\n",
    "#                 v1x = -v1x; v1y=-v1y\n",
    "#             if v2x<0:\n",
    "#                 v2x = -v2x; v2y = -v2y\n",
    "#             axarr[3].arrow(px,py,vlength*v1x,vlength*v1y,head_width=30)\n",
    "#             axarr[3].arrow(px,py,vlength*v2x,vlength*v2y,head_width=30)       \n",
    "            \n",
    "#         axarr[3].title.set_text('final vector')\n",
    "#         axarr[3].set_xlim(0,1280); axarr[3].set_ylim(0,720)\n",
    "#         axarr[3].invert_yaxis()\n",
    "\n",
    "        fig.suptitle(f'frame = {frame_idx}/{total_frames}')\n",
    "        writer.grab_frame()\n",
    "        \n",
    "        # progress bar\n",
    "        clear_output(wait=True)\n",
    "        print(f\"processing time = {end_processing_time - start_processing_time:.4f} s, GMM time = {end_gmm_time-start_gmm_time:.4f} s\")\n",
    "        print(f\"saving the {frame_idx}/{total_frames} frame\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        bar_width= 80\n",
    "        b = int(bar_width * frame_idx / total_frames)\n",
    "        l = bar_width - b\n",
    "        print(u\"\\u2588\" * int(b) + '-' * int(l),f'{frame_idx/total_frames*100:.2f}%')\n",
    "        print(f\"elapsed time = {elapsed_time/60:.2f} min, time remain = {elapsed_time/(1+frame_idx)*(total_frames-frame_idx)/60:.2f} min\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec265185",
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(f\"results/{bag_name}.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676180f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.342"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0057*2*30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
